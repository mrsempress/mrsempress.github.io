<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">


  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Notes," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="This is my blog. 新的一门课开始啦～ 感觉还不错啦～ 新的一门课，找首新歌吧～">
<meta name="keywords" content="Notes">
<meta property="og:type" content="article">
<meta property="og:title" content="Neural Networks and Deep Learning">
<meta property="og:url" content="http://mrsempress.top/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/index.html">
<meta property="og:site_name" content="Mrs_empress">
<meta property="og:description" content="This is my blog. 新的一门课开始啦～ 感觉还不错啦～ 新的一门课，找首新歌吧～">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://mrsempress.top/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/3.png">
<meta property="og:image" content="http://mrsempress.top/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/1.png">
<meta property="og:image" content="http://mrsempress.top/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/2.png">
<meta property="og:image" content="http://mrsempress.top/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/Logistic%20regression.png">
<meta property="og:image" content="http://mrsempress.top/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/4.png">
<meta property="og:updated_time" content="2018-11-29T07:05:53.012Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Neural Networks and Deep Learning">
<meta name="twitter:description" content="This is my blog. 新的一门课开始啦～ 感觉还不错啦～ 新的一门课，找首新歌吧～">
<meta name="twitter:image" content="http://mrsempress.top/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/3.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://mrsempress.top/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/"/>





  <title>Neural Networks and Deep Learning | Mrs_empress</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0b0957531a34243a173c768258ed03c4";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <a href="https://mrsempress.github.io/" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#fff; color:#151513; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Mrs_empress</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Your bright sun</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-poem">
          <a href="/poem" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br />
            
            poem
          </a>
        </li>
      
        
        <li class="menu-item menu-item-resume">
          <a href="http://mrsempress-certificate.oss-cn-beijing.aliyuncs.com/%E9%BB%84%E6%99%A8%E6%99%B0.pdf" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            resume
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://mrsempress.top/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mrs_empress">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mrs_empress">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Neural Networks and Deep Learning</h1>
        

        <div class="post-meta">
	  
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-12T08:49:56+08:00">
                2018-11-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/笔记/" itemprop="url" rel="index">
                    <span itemprop="name">笔记</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/" class="leancloud_visitors" data-flag-title="Neural Networks and Deep Learning">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>This is <a href="https://mrsempress.github.io" target="_blank" rel="external">my blog</a>.</p>
<p>新的一门课开始啦～</p>
<p>感觉还不错啦～</p>
<p>新的一门课，找首新歌吧～</p>
<a id="more"></a>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>



<h2 id="Suggestion"><a href="#Suggestion" class="headerlink" title="Suggestion"></a>Suggestion</h2><ul>
<li>多读文献</li>
<li>编程</li>
<li>培养自己的直觉，并且相信自己的直觉</li>
</ul>
<h2 id="What-is-Neural-Nerworks"><a href="#What-is-Neural-Nerworks" class="headerlink" title="What is Neural Nerworks"></a>What is Neural Nerworks</h2><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>具体可见之间文章<a href="http://mrsempress.top/2018/11/06/Machine-Learning-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/">手写数字识别</a></p>
<p>每层的激活函数可以不同</p>
<ul>
<li><p>线性整流函数(Rectified linear unit) RELU</p>
<p>但是在负数的时候，导数为0；因此出现了leaky Relu，eg.max(0.01z,z), the 0.01 can change，但后者不常使用</p>
<p><code>max(0,y)</code></p>
<p><img src="/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/3.png" alt=""></p>
</li>
<li><p>达到数据中心化的效果</p>
<p>一般来说，效果比sigmoid更好</p>
</li>
</ul>
<p>激活函数一般不用线性的，或者不用不用（就是$g(z)=z$）</p>
<p>这样会使隐藏层没有存在的意义，也就是说神经网络和没有学习能力一样，只存在着线性的惯性，多步可以合成一个大点的线性关系；</p>
<p>线性激活函数一般用在输出层，用来预测房价类型的问题</p>
<h3 id="Structured-Data"><a href="#Structured-Data" class="headerlink" title="Structured Data"></a>Structured Data</h3><p>给出结构化数据，每一个特征都有清晰的定义</p>
<p>每一个特征都有明确的数值</p>
<h3 id="Unstructured-Data"><a href="#Unstructured-Data" class="headerlink" title="Unstructured Data"></a>Unstructured Data</h3><p>非结构的，例如音频，图片，文字</p>
<p><strong>The iterative process of developing DL systems</strong>： Idea-&gt;Code-&gt;Experiment-&gt;Idea-&gt;….</p>
<h3 id="NN"><a href="#NN" class="headerlink" title="NN"></a>NN</h3><p>之后的博文会更新，更新完后，会在此加上链接</p>
<ul>
<li>Standard NN</li>
<li>CNN</li>
<li>RNN</li>
</ul>
<h2 id="Logistics-Regression-as-a-neural-network"><a href="#Logistics-Regression-as-a-neural-network" class="headerlink" title="Logistics Regression as a neural network"></a>Logistics Regression as a neural network</h2><p>It is a <strong>Binary classification</strong> （二分类问题）</p>
<p>这里只有两层（输入层不算）</p>
<p>在<a href="http://mrsempress.top/2018/10/30/Machine-Learning-regression-model/">Regression Model-Lesson6</a>提到过一些概念，现大致重述如下：</p>
<p><img src="/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/1.png" alt=""></p>
<p><img src="/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/2.png" alt=""></p>
<h3 id="optimization"><a href="#optimization" class="headerlink" title="optimization"></a>optimization</h3><p><strong>vectorization</strong></p>
<p>在<code>python</code>的<code>numpy</code>包中有许多内置函数，可以进行并行运算，比<code>for</code>循环更快</p>
<p>You can get time running time of one programm is to use <code>time.time()</code> method in package <code>time</code>. 单位<code>10^{-6}s</code></p>
<p>一些内置函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">cal = A.sum(axis=<span class="number">0</span>) <span class="comment"># 列求和，行压缩</span></div><div class="line">np.log(A, B)</div><div class="line">np.exp(A, B) <span class="comment"># the "math" library in deep learning because the inputs of the functions are real numbers. In deep learning we mostly use matrices and vectors. This is why numpy is more useful.</span></div><div class="line"></div><div class="line"><span class="comment"># 对于以下三种乘法，我将重点分析一下区别</span></div><div class="line">A * B <span class="comment"># 会进行广播原则，对应元素相乘</span></div><div class="line"></div><div class="line">np.dot(A, B) <span class="comment"># For 2-D arrays it is equivalent to matrix multiplication, and for 1-D arrays to inner product of vectors (without complex conjugation)【对应元素相乘再相加，见下面例子中的np.dot(c, a).而若A，B是matrix的时候，则需要大小满足矩阵相乘的条件</span></div><div class="line"></div><div class="line">np.multiply(A, B) <span class="comment"># 对应元素相乘，当矩阵的维度不相同时，会根据一定的广播规则将维数扩充到一致的形式. 如果不能广播相同的size，multiply就会失败</span></div><div class="line"></div><div class="line">x_norm = np.linalg.norm(x, ord =<span class="number">2</span>, axis=<span class="number">1</span>, keepdims=<span class="keyword">True</span>) <span class="comment"># 求范式</span></div><div class="line"><span class="comment"># ord几范式（默认二范式） 一范式：|x1|+...+|xn|	二范式：sqrt(x1^2+...+xn^2) 无穷范式: max(|xi|)</span></div><div class="line"><span class="comment"># axis=1表示按行向量处理，求多个行向量的范数；axis=0表示按列向量处理，求多个列向量的范数；axis=None表示矩阵范数</span></div><div class="line"><span class="comment"># keepdims True表示保持矩阵的二维特性，False相反</span></div></pre></td></tr></table></figure>
<p>给一下测试的结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])  <span class="comment"># (3,)</span></div><div class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) 	</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>b = np.array([[<span class="number">1</span>, <span class="number">2</span>,<span class="number">3</span>]]) <span class="comment"># (1,3)</span></div><div class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]])	</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>c = np.array([[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],[<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]]) <span class="comment"># (2,3)</span></div><div class="line">array([[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], </div><div class="line">       [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])		</div><div class="line"></div><div class="line"><span class="comment"># A * B </span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(a*b) <span class="comment"># 对应元素相乘</span></div><div class="line">[[<span class="number">1</span> <span class="number">4</span> <span class="number">9</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(a*c) <span class="comment"># 先进行广播原则，再对应元素相乘</span></div><div class="line">[[ <span class="number">4</span> <span class="number">10</span> <span class="number">18</span>]</div><div class="line"> [ <span class="number">7</span> <span class="number">16</span> <span class="number">27</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(c*a) <span class="comment"># 先进行广播原则，再对应元素相乘</span></div><div class="line">[[ <span class="number">4</span> <span class="number">10</span> <span class="number">18</span>]</div><div class="line"> [ <span class="number">7</span> <span class="number">16</span> <span class="number">27</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(b*c) <span class="comment"># 先进行广播原则，再对应元素相乘</span></div><div class="line">[[ <span class="number">4</span> <span class="number">10</span> <span class="number">18</span>]</div><div class="line"> [ <span class="number">7</span> <span class="number">16</span> <span class="number">27</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(c*b) <span class="comment"># 先进行广播原则，再对应元素相乘</span></div><div class="line">[[ <span class="number">4</span> <span class="number">10</span> <span class="number">18</span>]</div><div class="line"> [ <span class="number">7</span> <span class="number">16</span> <span class="number">27</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(b*a) <span class="comment"># 先进行广播原则，再对应元素相乘</span></div><div class="line">[[<span class="number">1</span> <span class="number">4</span> <span class="number">9</span>]]</div><div class="line"></div><div class="line"><span class="comment"># np.dot(A, B)</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(np.dot(a,b)) <span class="comment"># 不满足矩阵相乘概念 a(3,) b(1,3)注意a只是秩为1，它的shape很神奇哦</span></div><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"&lt;pyshell#32&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</div><div class="line">    print(np.dot(a,b))</div><div class="line">ValueError: shapes (<span class="number">3</span>,) <span class="keyword">and</span> (<span class="number">1</span>,<span class="number">3</span>) <span class="keyword">not</span> aligned: <span class="number">3</span> (dim <span class="number">0</span>) != <span class="number">1</span> (dim <span class="number">0</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(np.dot(b,a)) <span class="comment"># b(1,3) a(3, ) </span></div><div class="line">[<span class="number">14</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(np.dot(a,c)) <span class="comment"># 不满足矩阵相乘概念 a(3,) c(2,3)</span></div><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"&lt;pyshell#34&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</div><div class="line">    print(np.dot(a,c))</div><div class="line">ValueError: shapes (<span class="number">3</span>,) <span class="keyword">and</span> (<span class="number">2</span>,<span class="number">3</span>) <span class="keyword">not</span> aligned: <span class="number">3</span> (dim <span class="number">0</span>) != <span class="number">2</span> (dim <span class="number">0</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(np.dot(c, a)) <span class="comment"># c(2,3) a(3,)得到的不是两行哦！32=1*4+2*3*6	50=1*7+2*8+3*9</span></div><div class="line">[<span class="number">32</span> <span class="number">50</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(np.dot(b,c)) <span class="comment"># 不满足矩阵相乘概念 b(1,3) c(2,3)</span></div><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"&lt;pyshell#36&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</div><div class="line">    print(np.dot(b,c))</div><div class="line">ValueError: shapes (<span class="number">1</span>,<span class="number">3</span>) <span class="keyword">and</span> (<span class="number">2</span>,<span class="number">3</span>) <span class="keyword">not</span> aligned: <span class="number">3</span> (dim <span class="number">1</span>) != <span class="number">2</span> (dim <span class="number">0</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(np.dot(c,b)) <span class="comment"># 不满足矩阵相乘概念 c(2,3) b(1,3)</span></div><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"&lt;pyshell#37&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</div><div class="line">    print(np.dot(c,b))</div><div class="line">ValueError: shapes (<span class="number">2</span>,<span class="number">3</span>) <span class="keyword">and</span> (<span class="number">1</span>,<span class="number">3</span>) <span class="keyword">not</span> aligned: <span class="number">3</span> (dim <span class="number">1</span>) != <span class="number">1</span> (dim <span class="number">0</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>np.dot(c,b.T) <span class="comment"># c(2,3) b.T(3,1) 矩阵运算</span></div><div class="line">array([[<span class="number">32</span>],</div><div class="line">       [<span class="number">50</span>]])</div><div class="line"></div><div class="line"><span class="comment"># np.multiply(A, B)</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(np.multiply(a,b)) <span class="comment"># a(3, ) b(1,3)对应元素相乘</span></div><div class="line">[[<span class="number">1</span> <span class="number">4</span> <span class="number">9</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(np.multiply(b,a)) <span class="comment"># b(1,3) a(3, )对应元素相乘</span></div><div class="line">[[<span class="number">1</span> <span class="number">4</span> <span class="number">9</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(np.multiply(a,c)) <span class="comment"># a(3, ) c(2,3)对应元素相乘</span></div><div class="line">[[ <span class="number">4</span> <span class="number">10</span> <span class="number">18</span>]</div><div class="line"> [ <span class="number">7</span> <span class="number">16</span> <span class="number">27</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(np.multiply(c,a)) <span class="comment"># c(2,3) a(3, )对应元素相乘</span></div><div class="line">[[ <span class="number">4</span> <span class="number">10</span> <span class="number">18</span>]</div><div class="line"> [ <span class="number">7</span> <span class="number">16</span> <span class="number">27</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(np.multiply(b,c)) <span class="comment"># 先进行广播原则，再对应元素相乘</span></div><div class="line">[[ <span class="number">4</span> <span class="number">10</span> <span class="number">18</span>]</div><div class="line"> [ <span class="number">7</span> <span class="number">16</span> <span class="number">27</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(np.multiply(c,b)) <span class="comment"># 先进行广播原则，再对应元素相乘</span></div><div class="line">[[ <span class="number">4</span> <span class="number">10</span> <span class="number">18</span>]</div><div class="line"> [ <span class="number">7</span> <span class="number">16</span> <span class="number">27</span>]]</div></pre></td></tr></table></figure>
<p>在<code>python</code>中，若是一个向量加上一个常数，那么就等同于一个向量加上一个同样大小的向量，并且这个向量的值都是这个常数，这叫作<code>broadcasting</code></p>
<p>因此现在我们可以将方法二的进行向量化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(iterations):</div><div class="line">    <span class="comment"># 前向传播</span></div><div class="line">	Z = np.dot(W.T, X) <span class="comment"># X (n_x * m) W (n_x * 1)</span></div><div class="line">	A = sigma(Z) <span class="comment"># A (1 * m)</span></div><div class="line">    <span class="comment">#反向传播</span></div><div class="line">	dZ = A - Y <span class="comment"># Y (1 * m)</span></div><div class="line">	dW = <span class="number">1</span> / m * X * dZ.T <span class="comment"># dW (n_x * 1)</span></div><div class="line">	db = <span class="number">1</span> / m * np.sum(dZ) <span class="comment"># db (1 * 1)</span></div><div class="line">    <span class="comment"># 梯度下降</span></div><div class="line">    W = W - alpha * dW</div><div class="line">    b = b - alpha * db</div></pre></td></tr></table></figure>
<p>接下来，我们来了解一下<code>python</code>中的<code>broadcasting</code></p>
<p>当array的时候，(m,n) 要[+,-,*,/] (1,n)或者(m,1)的向量的时候，后者会扩展为(m,n)的向量，再进行运算</p>
<p>注意当用array创建的时候，用<code>np.random.randn(5,1)</code>而不是<code>np.random.randn(5)</code>，前者创建的是矩阵，后者创建的是秩为1的数组；后者是形如<code>[[1, 2, 3]]</code>前者是<code>[1, 2, 3]</code></p>
<h3 id="Computation-graph"><a href="#Computation-graph" class="headerlink" title="Computation graph"></a>Computation graph</h3><p>正向流程图，forward to compute the cost function</p>
<p>One step of backward propagation on a computation graph yields derivative of final output variable.后向计算导数，优化代价函数</p>
<p><strong>链式法则</strong>：感觉有点像蝴蝶效应（我瞎说的，就是一种影响的传播</p>
<p><img src="/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/Logistic%20regression.png" alt="逻辑回归"></p>
<h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><p>建议完成课程后的作业，感觉代码很棒呢！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># GRADED FUNCTION: sigmoid</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Compute the sigmoid of z</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    z -- A scalar or numpy array of any size.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Return:</span></div><div class="line"><span class="string">    s -- sigmoid(z)</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    s = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))</div><div class="line"></div><div class="line">    <span class="keyword">return</span> s</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># GRADED FUNCTION: initialize_with_zeros</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize_with_zeros</span><span class="params">(dim)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Argument:</span></div><div class="line"><span class="string">    dim -- size of the w vector we want (or number of parameters in this case)</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">    w -- initialized vector of shape (dim, 1)</span></div><div class="line"><span class="string">    b -- initialized scalar (corresponds to the bias)</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    w = np.zeros((dim, <span class="number">1</span>))</div><div class="line">    b = <span class="number">0</span></div><div class="line"></div><div class="line">    <span class="keyword">assert</span> (w.shape == (dim, <span class="number">1</span>))</div><div class="line">    <span class="keyword">assert</span> (isinstance(b, float) <span class="keyword">or</span> isinstance(b, int))</div><div class="line"></div><div class="line">    <span class="keyword">return</span> w, b</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># GRADED FUNCTION: propagate</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">propagate</span><span class="params">(w, b, X, Y)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Implement the cost function and its gradient for the propagation explained above</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    w -- weights, a numpy array of size (num_px * num_px * 3, 1)</span></div><div class="line"><span class="string">    b -- bias, a scalar</span></div><div class="line"><span class="string">    X -- data of size (num_px * num_px * 3, number of examples)</span></div><div class="line"><span class="string">    Y -- true "label" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Return:</span></div><div class="line"><span class="string">    cost -- negative log-likelihood cost for logistic regression</span></div><div class="line"><span class="string">    dw -- gradient of the loss with respect to w, thus same shape as w</span></div><div class="line"><span class="string">    db -- gradient of the loss with respect to b, thus same shape as b</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Tips:</span></div><div class="line"><span class="string">    - Write your code step by step for the propagation. np.log(), np.dot()</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    m = X.shape[<span class="number">1</span>]</div><div class="line"></div><div class="line">    <span class="comment"># FORWARD PROPAGATION (FROM X TO COST)</span></div><div class="line">    A = sigmoid(np.dot(w.T, X) + b)  <span class="comment"># compute activation</span></div><div class="line">    cost = - <span class="number">1</span> / m * np.sum(Y * np.log(A) + (<span class="number">1</span> - Y) * np.log((<span class="number">1</span> - A)))  <span class="comment"># compute cost</span></div><div class="line"></div><div class="line">    <span class="comment"># BACKWARD PROPAGATION (TO FIND GRAD)</span></div><div class="line">    dw = <span class="number">1</span> / m * np.dot(X, (A - Y).T)</div><div class="line">    db = <span class="number">1</span> / m * np.sum((A - Y))</div><div class="line"></div><div class="line">    <span class="keyword">assert</span> (dw.shape == w.shape)</div><div class="line">    <span class="keyword">assert</span> (db.dtype == float)</div><div class="line">    cost = np.squeeze(cost)</div><div class="line">    <span class="keyword">assert</span> (cost.shape == ())</div><div class="line"></div><div class="line">    grads = &#123;<span class="string">"dw"</span>: dw,</div><div class="line">             <span class="string">"db"</span>: db&#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> grads, cost</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># GRADED FUNCTION: optimize</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimize</span><span class="params">(w, b, X, Y, num_iterations, learning_rate, print_cost=False)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    This function optimizes w and b by running a gradient descent algorithm</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    w -- weights, a numpy array of size (num_px * num_px * 3, 1)</span></div><div class="line"><span class="string">    b -- bias, a scalar</span></div><div class="line"><span class="string">    X -- data of shape (num_px * num_px * 3, number of examples)</span></div><div class="line"><span class="string">    Y -- true "label" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)</span></div><div class="line"><span class="string">    num_iterations -- number of iterations of the optimization loop</span></div><div class="line"><span class="string">    learning_rate -- learning rate of the gradient descent update rule</span></div><div class="line"><span class="string">    print_cost -- True to print the loss every 100 steps</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">    params -- dictionary containing the weights w and bias b</span></div><div class="line"><span class="string">    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function</span></div><div class="line"><span class="string">    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Tips:</span></div><div class="line"><span class="string">    You basically need to write down two steps and iterate through them:</span></div><div class="line"><span class="string">        1) Calculate the cost and the gradient for the current parameters. Use propagate().</span></div><div class="line"><span class="string">        2) Update the parameters using gradient descent rule for w and b.</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    costs = []</div><div class="line"></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_iterations):</div><div class="line"></div><div class="line">        <span class="comment"># Cost and gradient calculation (≈ 1-4 lines of code)</span></div><div class="line">        grads, cost = propagate(w, b, X, Y)</div><div class="line"></div><div class="line">        <span class="comment"># Retrieve derivatives from grads</span></div><div class="line">        dw = grads[<span class="string">"dw"</span>]</div><div class="line">        db = grads[<span class="string">"db"</span>]</div><div class="line"></div><div class="line">        <span class="comment"># update rule (≈ 2 lines of code)</span></div><div class="line">        w = w - learning_rate * dw</div><div class="line">        b = b - learning_rate * db</div><div class="line"></div><div class="line">        <span class="comment"># Record the costs</span></div><div class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</div><div class="line">            costs.append(cost)</div><div class="line"></div><div class="line">        <span class="comment"># Print the cost every 100 training iterations</span></div><div class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">100</span> == <span class="number">0</span>:</div><div class="line">            print(<span class="string">"Cost after iteration %i: %f"</span> % (i, cost))</div><div class="line"></div><div class="line">    params = &#123;<span class="string">"w"</span>: w,</div><div class="line">              <span class="string">"b"</span>: b&#125;</div><div class="line"></div><div class="line">    grads = &#123;<span class="string">"dw"</span>: dw,</div><div class="line">             <span class="string">"db"</span>: db&#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> params, grads, costs</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># GRADED FUNCTION: predict</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(w, b, X)</span>:</span></div><div class="line">    <span class="string">'''</span></div><div class="line"><span class="string">    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    w -- weights, a numpy array of size (num_px * num_px * 3, 1)</span></div><div class="line"><span class="string">    b -- bias, a scalar</span></div><div class="line"><span class="string">    X -- data of size (num_px * num_px * 3, number of examples)</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X</span></div><div class="line"><span class="string">    '''</span></div><div class="line"></div><div class="line">    m = X.shape[<span class="number">1</span>]</div><div class="line">    Y_prediction = np.zeros((<span class="number">1</span>, m))</div><div class="line">    w = w.reshape(X.shape[<span class="number">0</span>], <span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="comment"># Compute vector "A" predicting the probabilities of a cat being present in the picture</span></div><div class="line">    <span class="comment">### START CODE HERE ### (≈ 1 line of code)</span></div><div class="line">    A = sigmoid(np.dot(w.T, X) + b)</div><div class="line">    <span class="comment">### END CODE HERE ###</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(A.shape[<span class="number">1</span>]):</div><div class="line"></div><div class="line">        <span class="comment"># Convert probabilities A[0,i] to actual predictions p[0,i]</span></div><div class="line">        <span class="comment">### START CODE HERE ### (≈ 4 lines of code)</span></div><div class="line">        <span class="keyword">if</span> A[<span class="number">0</span>, i] &gt; <span class="number">0.5</span>:</div><div class="line">            Y_prediction[<span class="number">0</span>, i] = <span class="number">1</span></div><div class="line">        <span class="comment">### END CODE HERE ###</span></div><div class="line"></div><div class="line">    <span class="keyword">assert</span> (Y_prediction.shape == (<span class="number">1</span>, m))</div><div class="line"></div><div class="line">    <span class="keyword">return</span> Y_prediction</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># GRADED FUNCTION: model</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X_train, Y_train, X_test, Y_test, num_iterations=<span class="number">2000</span>, learning_rate=<span class="number">0.5</span>, print_cost=False)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Builds the logistic regression model by calling the function you've implemented previously</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)</span></div><div class="line"><span class="string">    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)</span></div><div class="line"><span class="string">    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)</span></div><div class="line"><span class="string">    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)</span></div><div class="line"><span class="string">    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters</span></div><div class="line"><span class="string">    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()</span></div><div class="line"><span class="string">    print_cost -- Set to true to print the cost every 100 iterations</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">    d -- dictionary containing information about the model.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    </div><div class="line">    <span class="comment"># initialize parameters with zeros (≈ 1 line of code)</span></div><div class="line">    w, b = initialize_with_zeros(X_train.shape[<span class="number">0</span>])</div><div class="line"></div><div class="line">    <span class="comment"># Gradient descent (≈ 1 line of code)</span></div><div class="line">    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)</div><div class="line"></div><div class="line">    <span class="comment"># Retrieve parameters w and b from dictionary "parameters"</span></div><div class="line">    w = parameters[<span class="string">"w"</span>]</div><div class="line">    b = parameters[<span class="string">"b"</span>]</div><div class="line"></div><div class="line">    <span class="comment"># Predict test/train set examples (≈ 2 lines of code)</span></div><div class="line">    Y_prediction_test = predict(w, b, X_test)</div><div class="line">    Y_prediction_train = predict(w, b, X_train)</div><div class="line"></div><div class="line">    <span class="comment">### END CODE HERE ###</span></div><div class="line"></div><div class="line">    <span class="comment"># Print train/test Errors</span></div><div class="line">    print(<span class="string">"train accuracy: &#123;&#125; %"</span>.format(<span class="number">100</span> - np.mean(np.abs(Y_prediction_train - Y_train)) * <span class="number">100</span>))</div><div class="line">    print(<span class="string">"test accuracy: &#123;&#125; %"</span>.format(<span class="number">100</span> - np.mean(np.abs(Y_prediction_test - Y_test)) * <span class="number">100</span>))</div><div class="line"></div><div class="line">    d = &#123;<span class="string">"costs"</span>: costs,</div><div class="line">         <span class="string">"Y_prediction_test"</span>: Y_prediction_test,</div><div class="line">         <span class="string">"Y_prediction_train"</span>: Y_prediction_train,</div><div class="line">         <span class="string">"w"</span>: w,</div><div class="line">         <span class="string">"b"</span>: b,</div><div class="line">         <span class="string">"learning_rate"</span>: learning_rate,</div><div class="line">         <span class="string">"num_iterations"</span>: num_iterations&#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> d</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Loading the data (cat/non-cat)</span></div><div class="line">train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()</div><div class="line"></div><div class="line"><span class="comment"># get the information of sets</span></div><div class="line">m_train = train_set_x_orig.shape[<span class="number">0</span>]</div><div class="line">m_test = test_set_x_orig.shape[<span class="number">0</span>]</div><div class="line">num_px = train_set_x_orig.shape[<span class="number">1</span>]</div><div class="line"><span class="comment"># Reshape the training and test examples</span></div><div class="line"><span class="comment"># A trick when you want to flatten a matrix X of shape (a,b,c,d)</span></div><div class="line"><span class="comment"># to a matrix X_flatten of shape (b ∗∗ c ∗∗ d, a) is to use:</span></div><div class="line"><span class="comment"># X_flatten = X.reshape(X.shape[0], -1).T      # X.T is the transpose of X</span></div><div class="line"></div><div class="line">train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T</div><div class="line">test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T</div><div class="line"></div><div class="line"><span class="comment"># standardize dataset</span></div><div class="line">train_set_x = train_set_x_flatten/<span class="number">255.</span></div><div class="line">test_set_x = test_set_x_flatten/<span class="number">255.</span></div><div class="line"></div><div class="line"><span class="comment"># test learning rates</span></div><div class="line">learning_rates = [<span class="number">0.01</span>, <span class="number">0.001</span>, <span class="number">0.0001</span>]</div><div class="line">models = &#123;&#125;</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> learning_rates:</div><div class="line">    <span class="keyword">print</span> (<span class="string">"learning rate is: "</span> + str(i))</div><div class="line">    models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = <span class="number">1500</span>, learning_rate = i, print_cost = <span class="keyword">False</span>)</div><div class="line">    <span class="keyword">print</span> (<span class="string">'\n'</span> + <span class="string">"-------------------------------------------------------"</span> + <span class="string">'\n'</span>)</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> learning_rates:</div><div class="line">    plt.plot(np.squeeze(models[str(i)][<span class="string">"costs"</span>]), label= str(models[str(i)][<span class="string">"learning_rate"</span>]))</div><div class="line"></div><div class="line">plt.ylabel(<span class="string">'cost'</span>)</div><div class="line">plt.xlabel(<span class="string">'iterations (hundreds)'</span>)</div><div class="line"></div><div class="line">legend = plt.legend(loc=<span class="string">'upper center'</span>, shadow=<span class="keyword">True</span>)</div><div class="line">frame = legend.get_frame()</div><div class="line">frame.set_facecolor(<span class="string">'0.90'</span>)</div><div class="line">plt.show()</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># predict new pictures</span></div><div class="line">my_image = <span class="string">"avatar.jpg"</span>   <span class="comment"># change this to the name of your image file</span></div><div class="line">fname = <span class="string">"images/"</span> + my_image</div><div class="line">image = np.array(ndimage.imread(fname, flatten=<span class="keyword">False</span>))</div><div class="line">my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((<span class="number">1</span>, num_px*num_px*<span class="number">3</span>)).T</div><div class="line">d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = <span class="number">2000</span>, learning_rate = <span class="number">0.005</span>, print_cost = <span class="keyword">True</span>)</div><div class="line">my_predicted_image = predict(d[<span class="string">"w"</span>], d[<span class="string">"b"</span>], my_image)</div><div class="line"></div><div class="line">plt.imshow(image)</div><div class="line">print(<span class="string">"y = "</span> + str(np.squeeze(my_predicted_image)) + <span class="string">", your algorithm predicts a \""</span> + classes[int(np.squeeze(my_predicted_image)),].decode(<span class="string">"utf-8"</span>) +  <span class="string">"\" picture."</span>)</div></pre></td></tr></table></figure>
<h2 id="Standard-NN-标准神经网络"><a href="#Standard-NN-标准神经网络" class="headerlink" title="Standard NN(标准神经网络)"></a>Standard NN(标准神经网络)</h2><p>The general methodology to build a Neural Network is to:</p>
<ol>
<li>Define the neural network structure ( # of input units,  # of hidden units, etc). </li>
<li>Initialize the model’s parameters</li>
<li>Loop:<ul>
<li>Implement forward propagation</li>
<li>Compute loss</li>
<li>Implement backward propagation to get the gradients</li>
<li>Update parameters (gradient descent)</li>
</ul>
</li>
</ol>
<p>逻辑回归模型中，可以初始化为0，因为：</p>
<p>Logistic Regression <strong>doesn’t have a hidden layer</strong>. If you initialize the weights to zeros, the first example x fed in the logistic regression will output zero but the derivatives of the Logistic Regression <strong>depend on the input x</strong> (because there’s no hidden layer) which is not zero. So at the second iteration, the weights values follow x’s distribution and are different from each other if x is not a constant vector.</p>
<p>但是在神经网络中不可以，因为这样隐藏单元会一直是同样的功能，即隐藏神经元是对称的</p>
<p>由w影响的的，所以b可以初始化为0</p>
<p>而w则需使用<code>np.random.randn()</code>，同时，将这个生成的数，乘以一个较小的值，如0.01，这样通过计算得到的<code>z</code>绝对值较小，在激活函数中的斜率比较大，学习速率就可以大些。</p>
<p>同时每一层乘的数最好不相同。</p>
<p><img src="/2018/11/12/Neural-Networks-and-Deep-Learning-Neural-Networks/4.png" alt=""></p>
<p>在编程的时候，对于每一个变量最好写上<code>shape</code></p>
<p>第一层网络一般被认为是<strong>特征检测器</strong></p>
<p>the <strong>“cache”</strong> records values from the forward propagation units and sends it to the <strong>backward propagation</strong> units because it is needed to compute <strong>the chain rule derivatives.</strong></p>
<h3 id="Hyperparameters-超参数"><a href="#Hyperparameters-超参数" class="headerlink" title="Hyperparameters 超参数"></a>Hyperparameters 超参数</h3><p>都会影响W和b</p>
<ul>
<li>learning rate</li>
<li>Iteration</li>
<li>Hidden layers</li>
<li>Hidden units</li>
<li>choice of activation function</li>
</ul>
<p>在其他神经网络中我们还会遇到的超参数：</p>
<ul>
<li>Momentum term</li>
<li>Mini batch size</li>
<li>Regularizations Parameters </li>
<li>……</li>
</ul>
<p><strong>注：</strong>The <strong>deeper</strong> layers of a neural network are typically <strong>computing more complex features</strong> of the input than the earlier layers.</p>
<p>we <strong>cannot avoid</strong> a for <strong>loop</strong> iterating over the layers</p>
<p>To compute the function using a <strong>shallow</strong> network circuit, you will need <strong>a large network</strong> (where we measure size by the number of logic gates in the network), but to compute it using a <strong>deep</strong> network circuit, you need <strong>only an exponentially smaller</strong> network. </p>
<h2 id="CNN-卷积Convolutional神经网络"><a href="#CNN-卷积Convolutional神经网络" class="headerlink" title="CNN(卷积Convolutional神经网络)"></a>CNN(卷积Convolutional神经网络)</h2><p>在图像处理中，我们总是将卷积结构放在神经网络中，我们称这种处理方式为CNN</p>
<h2 id="RNN-递归Recurrent神经网络"><a href="#RNN-递归Recurrent神经网络" class="headerlink" title="RNN(递归Recurrent神经网络)"></a>RNN(递归Recurrent神经网络)</h2><p>序列的数据，我们一般用RNN；例如音频，语言</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>逻辑回归神经网络，刚开始看<code>machine learning</code>这个课程的时候，</p>
<p>含含糊糊，到写了机器学习的作业后，开始推导公式，</p>
<p>一步一步理解，</p>
<p>到现在再来一遍的时候，</p>
<p>感觉舒服多了</p>
<p>原来这门课只有四周很开心呐～</p>
<p>所以，我的零食什么时候到呀！</p>
<p>哦，对！我的解释器，emmm……</p>
<p>转载请注明出处，谢谢。<br><blockquote class="blockquote-center"><p>愿 我是你的小太阳</p>
</blockquote></p>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=17423740&auto=1&height=66"></iframe>

<!-- UY BEGIN -->
<p><div id="uyan_frame"></div></p>
<script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2142537"></script>

<!-- UY END -->

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>买糖果去喽</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechat.jpg" alt="Mrs_empress WeChat Pay"/>
        <p>WeChat Pay</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Notes/" rel="tag"><i class="fa fa-tag"></i> Notes</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/11/11/Machine-Learning-last-class/" rel="next" title="Machine-Learning-last-class">
                <i class="fa fa-chevron-left"></i> Machine-Learning-last-class
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/11/29/Neural-Networks-and-Deep-Learning-Improving-Deep-Neural-Networks/" rel="prev" title="Improving Deep Neural Networks">
                Improving Deep Neural Networks <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          
            <img class="site-author-image" itemprop="image"
              src="/images/avatar.jpg"
              alt="Mrs_empress" />
          
            <p class="site-author-name" itemprop="name">Mrs_empress</p>
            <p class="site-description motion-element" itemprop="description">Hope be better and better, wish be happy and happy!</p>
        </div>

        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives">
            
                <span class="site-state-item-count">100</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">40</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">70</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/mrsempress" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.facebook.com/chenxi.huang.56211" target="_blank" title="FB Page">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                    
                      FB Page
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/3309079767?refer_flag=1001030001_&nick=Mrs_empress_阡沫昕&is_hot=1" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                    
                      微博
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://tobiaslee.top" title="TobiasLee" target="_blank">TobiasLee</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://abcml.xin/" title="ZeZe" target="_blank">ZeZe</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://notes-hongbo.top" title="Bob" target="_blank">Bob</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://undefinedf.github.io/" title="Fjh" target="_blank">Fjh</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Suggestion"><span class="nav-number">1.</span> <span class="nav-text">Suggestion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#What-is-Neural-Nerworks"><span class="nav-number">2.</span> <span class="nav-text">What is Neural Nerworks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#激活函数"><span class="nav-number">2.1.</span> <span class="nav-text">激活函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Structured-Data"><span class="nav-number">2.2.</span> <span class="nav-text">Structured Data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Unstructured-Data"><span class="nav-number">2.3.</span> <span class="nav-text">Unstructured Data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NN"><span class="nav-number">2.4.</span> <span class="nav-text">NN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Logistics-Regression-as-a-neural-network"><span class="nav-number">3.</span> <span class="nav-text">Logistics Regression as a neural network</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#optimization"><span class="nav-number">3.1.</span> <span class="nav-text">optimization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Computation-graph"><span class="nav-number">3.2.</span> <span class="nav-text">Computation graph</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#python"><span class="nav-number">3.3.</span> <span class="nav-text">python</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Standard-NN-标准神经网络"><span class="nav-number">4.</span> <span class="nav-text">Standard NN(标准神经网络)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hyperparameters-超参数"><span class="nav-number">4.1.</span> <span class="nav-text">Hyperparameters 超参数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CNN-卷积Convolutional神经网络"><span class="nav-number">5.</span> <span class="nav-text">CNN(卷积Convolutional神经网络)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RNN-递归Recurrent神经网络"><span class="nav-number">6.</span> <span class="nav-text">RNN(递归Recurrent神经网络)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#后记"><span class="nav-number">7.</span> <span class="nav-text">后记</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2017 &mdash; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mrs_empress</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">Theme &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.2</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  








  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("73XX9zwrQOBeD6S0LGJO26Ac-gzGzoHsz", "92PFBxqwUfTSuVqrflFGaf5G");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
